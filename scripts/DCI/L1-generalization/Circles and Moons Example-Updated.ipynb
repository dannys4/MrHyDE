{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = [2, 1]\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"bright\")\n",
    "RC_PARAMS = {\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"axes.formatter.use_mathtext\": True,\n",
    "    \"figure.figsize\": (12, 8),\n",
    "#     \"figure.labelsize\": 16,\n",
    "#     \"figure.labelweight\": \"bold\",\n",
    "    \"figure.titleweight\": \"bold\",\n",
    "    \"figure.titlesize\": 18,\n",
    "    \"figure.dpi\": 300,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"legend.fancybox\": True,\n",
    "    \"text.usetex\": False,\n",
    "    \"mathtext.fontset\": \"stix\",\n",
    "    \"mathtext.default\": \"bf\",\n",
    "    \"font.family\": \"STIXGeneral\",\n",
    "    \"font.weight\": \"bold\",\n",
    "}\n",
    "plt.rcParams.update(RC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64851e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from distr_tools import mixture_dist,mv_iid_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7361db",
   "metadata": {},
   "source": [
    "Plotting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 4.\n",
    "folder = '../fig/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f9b5a",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b89d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "# compute for Gaussian Kernel 1D\n",
    "RK = 1/(2*np.sqrt(np.pi))\n",
    "mu2K = 1\n",
    "\n",
    "def compute_alpha2_factor(x):\n",
    "    # 6th and 4th derivative of standard normal distribution\n",
    "    phi6 = lambda x: (x ** 6 - 15 * x ** 4 + 45 * x ** 2 - 15) * sps.norm.pdf(x)\n",
    "    phi4 = lambda x: (x ** 4 - 6 * x ** 2 + 3) * sps.norm.pdf(x)\n",
    "    \n",
    "    # differences and data params\n",
    "    n = len(x)\n",
    "    diff_matrix = np.tile(x,(n,1))-np.tile(x,(n,1)).T # xi-xj for double dum\n",
    "    lam_iqr = sps.iqr(x)\n",
    "\n",
    "    # constants\n",
    "    a = 0.920*lam_iqr*n**(-1./7)\n",
    "    b = 0.912*lam_iqr*n**(-1./9)\n",
    "\n",
    "    # compute denominator\n",
    "    Tdb = np.sum(phi6(diff_matrix/b))\n",
    "    Tdb /= -(n*(n-1)*b**7)\n",
    "\n",
    "    # compute numerator\n",
    "    Sda = np.sum(phi4(diff_matrix/a))\n",
    "    Sda /= (n*(n-1)*a**5)\n",
    "\n",
    "    return 1.357*(Sda/Tdb)**(1./7)\n",
    "\n",
    "def js_eq12(x,h,alpha2_factor=None, RK=RK, SK=mu2K):\n",
    "    # 6th and 4th derivative of standard normal distribution\n",
    "    phi6 = lambda x: (x ** 6 - 15 * x ** 4 + 45 * x ** 2 - 15) * sps.norm.pdf(x)\n",
    "    phi4 = lambda x: (x ** 4 - 6 * x ** 2 + 3) * sps.norm.pdf(x)\n",
    "    \n",
    "    # differences and data params\n",
    "    n = len(x)\n",
    "    diff_matrix = np.tile(x,(n,1))-np.tile(x,(n,1)).T # xi-xj for double dum\n",
    "    \n",
    "    # alpha2 factor\n",
    "    if alpha2_factor is None:\n",
    "        alpha2 = compute_alpha2_factor(x)\n",
    "    else:\n",
    "        alpha2 = alpha2_factor\n",
    "        \n",
    "    # compute Sd(alpha2(h))\n",
    "    alpha2h = alpha2*h**(5./7)\n",
    "    Sdalpha2h = np.sum(phi4(diff_matrix/alpha2h))\n",
    "    Sdalpha2h /= (n*(n-1)*alpha2h**5)\n",
    "    \n",
    "    # eq. 12 from Sheather and Jones (1991) paper: goal is to find the zero\n",
    "    output = (RK/(SK**2*Sdalpha2h))**(1./5)*n**(-1./5)-h\n",
    "    \n",
    "    return output\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bca1dd",
   "metadata": {},
   "source": [
    "## Problem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb6a23",
   "metadata": {},
   "source": [
    "Suppose our model of interest is the following map from $\\mathbb{R}^4\\rightarrow\\mathbb{R}^2$:\n",
    "\n",
    "\\begin{align}\n",
    "Q(r,\\theta,c_x,c_y)=\\begin{bmatrix}r\\cos\\theta \\\\ r\\sin\\theta \\end{bmatrix} + \\begin{bmatrix} c_x \\\\ c_y \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "This model creates circles of radius $r$ around centers $c:=(c_x,c_y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(lam):\n",
    "    r,th,xeps,yeps = lam.T\n",
    "    return np.stack([r*np.cos(th)+xeps,r*np.sin(th)+yeps]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d1f02",
   "metadata": {},
   "source": [
    "For this example, we suppose that we have prior knowledge of three potential centers for the circle,\n",
    "\n",
    "$$\\left\\{c_1,c_2,c_3\\right\\}=\\left\\{(-1,0.5),(0,0),(1,0.5)\\right\\}$$\n",
    "\n",
    "but there is some uncertainty in these locations. To be specific, we assume that\n",
    "\n",
    "\\begin{align}\n",
    "c\\sim \\sum_{k=1}^Kw_k N(c_k,\\Sigma),\n",
    "\\end{align}\n",
    "\n",
    "i.e., a Gaussian mixture model where $\\Sigma=\\sigma^2 I$ represents the uncertainty in the locations $c_k$ and $w_k$ are initial probability weights for each circle.\n",
    "\n",
    "Our initial assumptions for the distribution of radii and angle sweep are $r\\sim U[0.75,1.25]$ and $\\theta\\sim U[0,2\\pi]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_init_pdf:\n",
    "    '''\n",
    "    Defines the custom initial pdf for this example\n",
    "    '''\n",
    "    def __init__(self,r_dist,th_dist,cxy_dist):\n",
    "        self.r_dist = r_dist\n",
    "        self.th_dist = th_dist\n",
    "        self.cxy_dist = cxy_dist\n",
    "    \n",
    "    def logpdf(self,r_th_cxy):\n",
    "        ''' Computes log pdf '''\n",
    "        r,th,cx,cy = r_th_cxy.T\n",
    "        cxy = np.column_stack([cx,cy])\n",
    "        out = self.r_dist.logpdf(r)+self.th_dist.logpdf(th)\n",
    "        out += self.cxy_dist.logpdf(cxy)\n",
    "        return out\n",
    "    \n",
    "    def pdf(self,r_th_cxy):\n",
    "        ''' Computes pdf '''\n",
    "        return np.exp(self.logpdf(r_th_cxy))\n",
    "    \n",
    "    def rvs(self,size=1,random_state=None):\n",
    "        ''' Generates random initial sample '''\n",
    "        if (random_state == None) or (type(random_state)==int):\n",
    "            rng = np.random.default_rng(random_state)\n",
    "        elif type(random_state)==np.random.Generator:\n",
    "            rng = random_state\n",
    "        else:\n",
    "            raise ValueError ('random_state must be an integer or numpy.random.Generator object.')            \n",
    "        out = np.column_stack([dist.rvs(size,random_state=rng) for dist in [self.r_dist,self.th_dist,self.cxy_dist]])\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial distributions\n",
    "r_init = sps.uniform(0.65,0.65)\n",
    "th_init = sps.uniform(0,2*np.pi)\n",
    "\n",
    "# center locations and distribution\n",
    "init_center = [np.zeros(2),np.array([1,0.5]),np.array([-1,0.5])]\n",
    "center_init = mixture_dist([sps.multivariate_normal(mu,0.005*np.eye(2)) for mu in init_center],\n",
    "                           np.ones(len(init_center))/len(init_center),multi=True)\n",
    "\n",
    "# define the initial distribution\n",
    "init_dist = custom_init_pdf(r_init,th_init,center_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afaaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial sample\n",
    "rng = np.random.default_rng(523230125)\n",
    "n_init = 15000\n",
    "init_sample = init_dist.rvs(n_init)\n",
    "\n",
    "# plotting visualization values\n",
    "lam_dict = {'r': np.linspace(r_init.support()[0]-0.25,r_init.support()[1]+0.25,250),\n",
    "            'th': np.linspace(th_init.support()[0]-0.25,th_init.support()[1]+0.25,250)}\n",
    "cx,cy = [np.linspace(-1.5,1.5,150+i) for i in range(2)]\n",
    "Cx,Cy = np.meshgrid(cx,cy)\n",
    "Cxy_eval = np.stack([Cx.reshape(-1,),Cy.reshape(-1,)],axis=-1)\n",
    "lam_dict['c'] = (Cx,Cy,Cxy_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot check initial distributions\n",
    "fig, axes = plt.subplots(1,3)\n",
    "fig.set_figwidth(4*3)\n",
    "for i,(key,ax) in enumerate(zip(lam_dict.keys(),axes)):\n",
    "    if key=='c':\n",
    "        X,Y,XY_eval = lam_dict[key]\n",
    "        this_probs = init_dist.cxy_dist.pdf(XY_eval).reshape(X.shape)\n",
    "        ax.scatter(init_sample[:,-2],init_sample[:,-1])\n",
    "        ax.contour(X,Y,this_probs)\n",
    "    else:\n",
    "        ax.hist(init_sample[:,i],density=True,edgecolor='gray',alpha=0.2)\n",
    "        this_x = lam_dict[key]\n",
    "        ax.plot(this_x,[init_dist.r_dist,init_dist.th_dist][i].pdf(this_x))\n",
    "    \n",
    "    ax.set_title('Init Dist: ${}$'.format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3e510",
   "metadata": {},
   "source": [
    "These initial distributions produce the following predicted circle values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predicted sample\n",
    "pred_sample = Q(init_sample)\n",
    "\n",
    "# plot values for data space\n",
    "qx,qy = [np.linspace(-2.5,2.5,150),np.linspace(-1.5,2,151)]\n",
    "Qx,Qy = np.meshgrid(qx,qy)\n",
    "Qxy_eval = np.stack([Qx.reshape(-1,),Qy.reshape(-1,)],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot check predicted sample\n",
    "plt.scatter(*pred_sample.T,alpha=0.5)\n",
    "plt.title(\"Pred Sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3623804",
   "metadata": {},
   "source": [
    "Suppose we observe data from the \"dual moons\" dataset. We want to find an updated distribution of radii, angles, and centers which is consistent with this observed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b494e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample observed distribution\n",
    "n_obs = 500\n",
    "moon_noise = 0.05\n",
    "obs_sample,moon_classes = datasets.make_moons(n_samples=n_obs,noise=moon_noise,random_state=5743203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218200f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot check predictability assumption\n",
    "plt.title(\"Obs Sample\")\n",
    "plt.scatter(*pred_sample.T,alpha=0.15,label='Pred')\n",
    "plt.scatter(*obs_sample.T,alpha=0.5,label='Obs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a2141",
   "metadata": {},
   "source": [
    "### Nice Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c484ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_setup_fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "ex_setup_fig.set_figwidth(5)\n",
    "ex_setup_fig.set_figheight(2.5)\n",
    "\n",
    "for i,ax in enumerate([ax1,ax2]):\n",
    "    ax.scatter(*pred_sample.T,label='Pred',alpha=[0.1,0.01][i])\n",
    "    ax.set_title(['Predicted','Observed'][i],fontsize=14)\n",
    "    ax.set_xlabel('$q_1$',fontsize=14)\n",
    "    ax.set_ylabel('$q_2$',fontsize=14)\n",
    "    \n",
    "ax2.scatter(*obs_sample.T,label='Obs',alpha=0.2)\n",
    "ex_setup_fig.tight_layout()\n",
    "ex_setup_fig\n",
    "\n",
    "name_kLmmd_fig = 'kLmmd_fig_setup'\n",
    "ex_setup_fig.savefig(folder+name_kLmmd_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2a808",
   "metadata": {},
   "source": [
    "# Scikit-Learn KDE to Approximate Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d7280",
   "metadata": {},
   "source": [
    "In this part of the example, we will use scikit-learn's KDE functions to approximate the observed and predicted distributions.\n",
    "\n",
    "In particular, we will compare how the choice of bandwidth affects the quality of the solution and demonstrate how optimizing the bandwidth in terms of the KL-divergence leads to a better quality result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from scipy.spatial.distance import cdist # for definition of MMD\n",
    "\n",
    "sk_rand_seed = 90123122 # random seed for sklearn reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for computing the maximum mean discrepancy\n",
    "def my_rbf_kernel(valsA,valsB):\n",
    "    gamma = 1.0/valsA.shape[1]\n",
    "    K = cdist(valsA,valsB,'sqeuclidean')\n",
    "    K *= -gamma\n",
    "    np.exp(K,K)\n",
    "    return K\n",
    "\n",
    "def my_mmd(valsA,valsB):\n",
    "    mmd = 0.\n",
    "    mmd += np.mean(my_rbf_kernel(valsA,valsA))\n",
    "    mmd += np.mean(my_rbf_kernel(valsB,valsB))\n",
    "    mmd += -2*np.mean(my_rbf_kernel(valsA,valsB))\n",
    "    return np.sqrt(mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e60972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the appropriate observed bandwidths\n",
    "bw_init = n_obs**(-1/(2+4))*np.std(obs_sample,axis=0).mean()\n",
    "obs_kde_silver = KernelDensity(kernel='gaussian',bandwidth=bw_init)\n",
    "obs_kde = KernelDensity(kernel='gaussian',bandwidth=bw_init)\n",
    "obs_SS = ShuffleSplit(n_splits=10,test_size=0.2,random_state=sk_rand_seed)\n",
    "bw_search = GridSearchCV(obs_kde,{'bandwidth': np.geomspace(moon_noise/2,bw_init,10)},\n",
    "                        refit=False,cv=obs_SS)\n",
    "bw_search.fit(obs_sample)\n",
    "obs_kde.bandwidth = bw_search.best_params_['bandwidth']\n",
    "print('Init. bw = ', obs_kde_silver.bandwidth)\n",
    "print('Obs. bw = ', obs_kde.bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb384802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the appropriate predicted bandwidths\n",
    "bw_init = n_init**(-1/(2+4))*np.std(pred_sample,axis=0).mean()\n",
    "pred_kde = KernelDensity(kernel='gaussian',bandwidth=bw_init)\n",
    "pred_SS = ShuffleSplit(n_splits=10,test_size=0.2,random_state=sk_rand_seed)\n",
    "bw_search = GridSearchCV(pred_kde,{'bandwidth': np.geomspace(moon_noise,bw_init,10)},\n",
    "                         refit=False,cv=pred_SS)\n",
    "bw_search.fit(pred_sample)\n",
    "pred_kde.bandwidth = bw_search.best_params_['bandwidth']\n",
    "# pred_kde.bandwidth = bw_init\n",
    "print('Pred. bw = ',pred_kde.bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the models and evaluate the pdfs\n",
    "obs_kde_silver.fit(obs_sample)\n",
    "obs_pdf_silver = np.exp(obs_kde_silver.score_samples(Qxy_eval)).reshape(Qx.shape)\n",
    "\n",
    "obs_kde.fit(obs_sample)\n",
    "obs_pdf_kde = np.exp(obs_kde.score_samples(Qxy_eval)).reshape(Qx.shape)\n",
    "\n",
    "pred_kde.fit(pred_sample)\n",
    "pred_pdf_kde = np.exp(pred_kde.score_samples(Qxy_eval)).reshape(Qx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot check predictability assumption\n",
    "plt.title(\"Obs Sample\")\n",
    "plt.scatter(*pred_sample.T,alpha=0.15,label='Pred')\n",
    "plt.scatter(*obs_sample.T,alpha=0.5,label='Obs')\n",
    "# plt.contour(Qx,Qy,obs_pdf_kde)\n",
    "plt.contour(Qx,Qy,pred_pdf_kde)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306861f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MMD between observed and original sample\n",
    "n_test = int(5e3)\n",
    "obs_kde_resample = obs_kde_silver.sample(n_test)\n",
    "this_mmd = my_mmd(obs_kde_resample,obs_sample)\n",
    "print(this_mmd)\n",
    "plt.scatter(*pred_sample.T,alpha=0.15,label='Pred')\n",
    "plt.scatter(*obs_kde_resample.T,color='xkcd:salmon',alpha=0.3,edgecolor='k')\n",
    "plt.scatter(*obs_sample.T,alpha=0.5,label='Obs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MMD between observed and original sample\n",
    "n_test = int(5e3)\n",
    "obs_kde_resample = obs_kde.sample(n_test)\n",
    "this_mmd = my_mmd(obs_kde_resample,obs_sample)\n",
    "print(this_mmd)\n",
    "plt.scatter(*pred_sample.T,alpha=0.15,label='Pred')\n",
    "plt.scatter(*obs_kde_resample.T,color='xkcd:salmon',alpha=0.3,edgecolor='k')\n",
    "plt.scatter(*obs_sample.T,alpha=0.5,label='Obs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dcbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = int(5e3)\n",
    "pred_kde_resample = pred_kde.sample(n_test)\n",
    "this_mmd = my_mmd(pred_kde_resample,pred_sample)\n",
    "print(this_mmd)\n",
    "plt.scatter(*pred_sample.T,alpha=0.15,label='Pred')\n",
    "plt.scatter(*pred_kde_resample.T,color='xkcd:purple',alpha=0.3)\n",
    "plt.scatter(*obs_sample.T,alpha=0.5,label='Obs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20424348",
   "metadata": {},
   "source": [
    "### Updated Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_silver = np.exp(obs_kde_silver.score_samples(pred_sample))/np.exp(pred_kde.score_samples(pred_sample))\n",
    "r_cross = np.exp(obs_kde.score_samples(pred_sample))/np.exp(pred_kde.score_samples(pred_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_silver.mean())\n",
    "print(r_cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d05f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute an updated sample\n",
    "update_dict = {}\n",
    "\n",
    "for item in ['sr','cv']:\n",
    "    # accept-reject\n",
    "    this_r = r_silver if item=='sr' else r_cross\n",
    "    M = np.max(this_r)\n",
    "    t = rng.uniform(0,1,pred_sample.shape[0])\n",
    "    accept_reject = np.less_equal(t,this_r/M)\n",
    "    print('Accepted: ',np.sum(accept_reject))\n",
    "    print('Accept ratio: ',np.sum(accept_reject)/len(accept_reject))\n",
    "\n",
    "    update_dict[item] = init_sample[accept_reject,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f662da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheather-jones bandwidths\n",
    "h_sj_dict = {'r': {'sr': None, 'cv': None},\n",
    "             'th': {'sr': None, 'cv': None}}\n",
    "for i,p in enumerate(h_sj_dict.keys()):\n",
    "    for item in h_sj_dict[p].keys():\n",
    "        this_sample = update_dict[item][:,i]\n",
    "\n",
    "        # compute constant factor from data\n",
    "        a2_fact = compute_alpha2_factor(this_sample)\n",
    "        h_init = np.std(this_sample,ddof=1)*(3/4*len(this_sample))**(-1./5) # silverman's rule\n",
    "\n",
    "        # solve for the zero\n",
    "        result = fsolve(lambda h: js_eq12(this_sample,h,alpha2_factor=a2_fact),\n",
    "                        x0 = h_init)\n",
    "\n",
    "        # put float at end of list\n",
    "        h_sj_dict[p][item] = float(result)/np.std(this_sample,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854066e",
   "metadata": {},
   "source": [
    "# Sklearn GMM Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e6289",
   "metadata": {},
   "source": [
    "The GMM with 10 components also uses maximum likelihood (or minimizing the KL-divergence) to fit the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM model\n",
    "obs_GMM = GaussianMixture(n_components=10,random_state=sk_rand_seed)\n",
    "\n",
    "# fit model\n",
    "obs_GMM.fit(obs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_pdf_GMM = np.exp(obs_GMM.score_samples(Qxy_eval)).reshape(Qx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92fb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot check predictability assumption\n",
    "# plt.title(\"Obs Sample\")\n",
    "# plt.scatter(*pred_sample.T,alpha=0.15,label='Pred')\n",
    "# plt.scatter(*obs_sample.T,alpha=0.5,label='Obs')\n",
    "# # plt.contour(Qx,Qy,obs_pdf_kde)\n",
    "# plt.contour(Qx,Qy,obs_pdf_GMM)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ebe31",
   "metadata": {},
   "source": [
    "### KDE Nice Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a462b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_obsKDE_fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "ex_obsKDE_fig.set_figwidth(8.5*2/3)\n",
    "ex_obsKDE_fig.set_figheight(3.0)\n",
    "for i,ax in enumerate([ax1,ax2]):\n",
    "    ax.scatter(*pred_sample.T,label='Pred',alpha=0.01)\n",
    "    ax.set_title(['Silverman\\'s','Cross-Validation','GMM'][i], fontsize=16)\n",
    "    ax.set_xlabel('$q_1$',fontsize=20)\n",
    "    ax.set_ylabel('$q_2$',fontsize=20)\n",
    "    ax.scatter(*obs_sample.T,label='Obs',alpha=0.2)\n",
    "    conts = ax.contour(Qx,Qy,[obs_pdf_silver,obs_pdf_kde,obs_pdf_GMM][i],\n",
    "                       vmin=0,extend='both')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    if i==0:\n",
    "        this_cont = conts.levels[3]\n",
    "#     ax.clabel(conts,conts.levels,inline=True)\n",
    "\n",
    "# plot a problem area\n",
    "xlims = np.argwhere(np.logical_and(Qx[0,:]>0,Qx[0,:]<1))[[0,-1]].reshape(-1,)\n",
    "ylims = np.argwhere(np.logical_and(Qy[:,0]>-0.25,Qy[:,0]<0.65))[[0,-1]].reshape(-1,)\n",
    "\n",
    "# ax1.contourf(Qx[slice(*ylims),slice(*xlims)],\n",
    "#              Qy[slice(*ylims),slice(*xlims)],\n",
    "#              obs_pdf_silver[slice(*ylims),slice(*xlims)],\n",
    "#              [0,this_cont],colors=['xkcd:neon red'],alpha=0.75)\n",
    "# ax1.annotate('',(0.5,0.35),(1,1),\n",
    "#              arrowprops=dict(edgecolor='k',facecolor='k',\n",
    "#                              width=1,headwidth=8,headlength=6))\n",
    "\n",
    "# save fig in tightlayout\n",
    "ex_obsKDE_fig.tight_layout()\n",
    "\n",
    "\n",
    "name_kLmmd_OBS = 'kLmmd_fig_obsKDE'\n",
    "ex_obsKDE_fig.savefig(folder+name_kLmmd_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb39034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_obsGMM_fig, (ax1) = plt.subplots(1,1)\n",
    "# ex_obsGMM_fig.set_figwidth(2.5)\n",
    "# ex_obsGMM_fig.set_figheight(2.5)\n",
    "\n",
    "# ax1.scatter(*pred_sample.T,label='Pred',alpha=0.01)\n",
    "# ax1.set_title('GMM of Obs.')\n",
    "# ax1.set_xlabel('$q_1$')\n",
    "# ax1.set_ylabel('$q_2$')\n",
    "# ax1.scatter(*obs_sample.T,label='Obs',alpha=0.2)\n",
    "# conts = ax1.contour(Qx,Qy,obs_pdf_GMM,\n",
    "#                    vmin=0,extend='both')\n",
    "\n",
    "# # save fig in tightlayout\n",
    "# ex_obsGMM_fig.tight_layout()\n",
    "\n",
    "\n",
    "# name_kLmmd_GMM = 'kLmmd_fig_obsGMM'\n",
    "# ex_obsGMM_fig.savefig(folder+name_kLmmd_GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm update parameters\n",
    "r_dict = {'sr': r_silver, 'cv': r_cross}\n",
    "r_dict['gmm'] = np.exp(obs_GMM.score_samples(pred_sample))/ np.exp(pred_kde.score_samples(pred_sample))\n",
    "\n",
    "# accept-reject\n",
    "this_r = r_dict['gmm']\n",
    "M = np.max(this_r)\n",
    "t = rng.uniform(0,1,pred_sample.shape[0])\n",
    "accept_reject = np.less_equal(t,this_r/M)\n",
    "print('Accepted: ',np.sum(accept_reject))\n",
    "print('Accept ratio: ',np.sum(accept_reject)/len(accept_reject))\n",
    "\n",
    "update_dict['gmm'] = init_sample[accept_reject,:]\n",
    "\n",
    "# compute optimal bandwidth\n",
    "for i,p in enumerate(h_sj_dict.keys()):\n",
    "    this_sample = update_dict['gmm'][:,i]\n",
    "\n",
    "    # compute constant factor from data\n",
    "    a2_fact = compute_alpha2_factor(this_sample)\n",
    "    h_init = np.std(this_sample,ddof=1)*(3/4*len(this_sample))**(-1./5) # silverman's rule\n",
    "\n",
    "    # solve for the zero\n",
    "    result = fsolve(lambda h: js_eq12(this_sample,h,alpha2_factor=a2_fact),\n",
    "                    x0 = h_init)\n",
    "\n",
    "    # put float at end of list\n",
    "    h_sj_dict[p]['gmm'] = float(result)/np.std(this_sample,ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd508359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot check update distributions\n",
    "# ex_up2_fig, axes = plt.subplots(1,2)\n",
    "# ex_up2_fig.set_figwidth(3.5*2)\n",
    "# ex_up2_fig.set_figheight(3)\n",
    "\n",
    "# label_dict = {'cv':'Update KDE $(h_{cv})$','gmm':'Update GMM'}\n",
    "# title_dict = {'r': '$\\\\lambda_1$','th':'$\\\\lambda_2$'}\n",
    "# for i,ax in enumerate(axes):\n",
    "#     for j,item in enumerate(['cv','gmm']):\n",
    "# #         ax.hist(update_dict[item][:,i],density=True,edgecolor='gray',alpha=0.2)            \n",
    "#         key = ['r','th'][i]\n",
    "#         this_x = lam_dict[key]\n",
    "#         this_kde = sps.gaussian_kde(init_sample[:,i],\n",
    "#                                     weights=r_dict[item],\n",
    "#                                     bw_method=h_sj_dict[key][item])\n",
    "#         ax.plot(this_x,this_kde.pdf(this_x),\n",
    "#                 label=label_dict[item],color=['C3','C4'][j])\n",
    "#     ax.plot(this_x,[init_dist.r_dist,init_dist.th_dist][i].pdf(this_x),color='C0',\n",
    "#             zorder=-3,label='Initial',ls='--',alpha=0.5)\n",
    "#     ax.set_title('Update Marginal: {}'.format(title_dict[key]))\n",
    "#     ax.legend()\n",
    "\n",
    "# ex_up2_fig.tight_layout()\n",
    "# name_kLmmd_UP2 = 'kLmmd_fig_UP2'\n",
    "# # ex_up2_fig.savefig(folder+name_kLmmd_UP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(plt.rcParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32a596",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot check update distributions\n",
    "ex_up1_fig, axes = plt.subplots(1,2)\n",
    "ex_up1_fig.set_figwidth(4*2)\n",
    "ex_up1_fig.set_figheight(4)\n",
    "\n",
    "label_dict = {'sr':'Approx. of $\\\\pi_{up}$ ($h_{silver}$ for $\\\\pi_{obs}$)','cv':'Approx. of $\\\\pi_{up}$ ($h_{cv}$ for $\\\\pi_{obs}$)','gmm':'Update GMM'}\n",
    "title_dict = {'r': '$\\\\lambda_1$','th':'$\\\\lambda_2$','c':'$(\\\\lambda_3,\\\\lambda_4)$'}\n",
    "for j,item in enumerate(['sr','cv']):\n",
    "    for i,(key,ax) in enumerate(zip(lam_dict.keys(),axes)):\n",
    "        if key=='c':\n",
    "            continue\n",
    "            X,Y,XY_eval = lam_dict[key]\n",
    "            this_kde = sps.gaussian_kde(init_sample[:,-2::].T,weights=r_dict[item])\n",
    "            this_probs = this_kde.pdf(XY_eval.T).reshape(X.shape)\n",
    "            ax.scatter(update_dict[item][:,-2],update_dict[item][:,-1],\n",
    "                       alpha=0.45,label=label_dict[item],color=['C1','C3','C4'][j])\n",
    "            if j==1:\n",
    "                ax.contour(X,Y,this_probs)\n",
    "        else:\n",
    "#             ax.hist(update_dict[item][:,i],density=True,edgecolor='gray',alpha=0.2)\n",
    "            this_x = lam_dict[key]\n",
    "            this_kde = sps.gaussian_kde(init_sample[:,i],\n",
    "                                        weights=r_dict[item],\n",
    "                                        bw_method=h_sj_dict[key][item])\n",
    "            ax.plot(this_x,this_kde.pdf(this_x),\n",
    "                    label=label_dict[item],color=['C1','C4','C3'][j])\n",
    "            if j==1:\n",
    "                ax.plot(this_x,[init_dist.r_dist,init_dist.th_dist][i].pdf(this_x),color='C0',\n",
    "                        zorder=-5,label='Initial',ls='--',alpha=0.5)\n",
    "        if j==0:\n",
    "            ax.set_title('Update Marginal: {}'.format(title_dict[key]))\n",
    "for ax in axes:\n",
    "    ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    # only show 4 ticks\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(4))\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(4))\n",
    "    # ax.legend(loc='lower right')\n",
    "\n",
    "\n",
    "\n",
    "# Add Legend\n",
    "from matplotlib.lines import Line2D\n",
    "line_styles = ['-', '-', '-', '--']\n",
    "line_labels = list(label_dict.values()) + ['$\\\\pi_{init}$']\n",
    "colours = ['C1', 'C4','C3', 'C0']\n",
    "handles = []\n",
    "for idx in [0,1,2,3]:\n",
    "    handles.append(Line2D([0], [0], color=colours[idx], ls=line_styles[idx],alpha=[1,1,1,0.5][idx]))\n",
    "ex_up1_fig.legend(handles=[handles[k] for k in [0,1,3]],\n",
    "                  labels=[line_labels[k] for k in [0,1,3]],\n",
    "                  loc='lower center',\n",
    "                  ncol=4,\n",
    "                  frameon=False,\n",
    "                  handlelength=1.5,\n",
    "                  handletextpad = 0.4,\n",
    "                  columnspacing=1.7,\n",
    "                  prop={'size': 14})\n",
    "\n",
    "ex_up1_fig.patch.set_facecolor('white')\n",
    "\n",
    "# Save figure\n",
    "ex_up1_fig.tight_layout()\n",
    "ex_up1_fig.subplots_adjust(bottom=0.2)\n",
    "name_kLmmd_UP1 = 'kLmmd_fig_UP1'\n",
    "ex_up1_fig.savefig(folder+name_kLmmd_UP1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27875c61",
   "metadata": {},
   "source": [
    "# Generate Updated Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab75da5",
   "metadata": {},
   "source": [
    "Here we generate updated samples for the KDE and GMM in order to compare these in monte-carlo approximations of the KL-divergence or the IPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dci_sk_dist:\n",
    "    def __init__(self,init_dist,obs_dist,pred_dist,Q):\n",
    "        self.Q = Q\n",
    "        self.init_dist = init_dist\n",
    "        self.obs_dist = obs_dist\n",
    "        self.pred_dist = pred_dist\n",
    "    \n",
    "    def logpdf(self,lam):\n",
    "        q = self.Q(lam)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):        \n",
    "            init_logpdf = self.init_dist.logpdf(lam)\n",
    "            obs_logpdf = self.obs_dist.score_samples(q)\n",
    "            pred_logpdf = self.pred_dist.score_samples(q)\n",
    "            output = init_logpdf+obs_logpdf-pred_logpdf\n",
    "        return output\n",
    "    \n",
    "    def pdf(self,lam):\n",
    "        return np.exp(self.logpdf(lam))\n",
    "    \n",
    "    def accept_reject(self,lam_init,probs_return=False,random_state=None):\n",
    "        # reproducibility\n",
    "        if (random_state == None) or (type(random_state)==int):\n",
    "            rng = np.random.default_rng(random_state)\n",
    "        elif type(random_state)==np.random.Generator:\n",
    "            rng = random_state\n",
    "        else:\n",
    "            raise ValueError ('random_state must be an integer or numpy.random.Generator object.')            \n",
    "\n",
    "        # evaluate accept-reject algorithm\n",
    "        # first get r value\n",
    "        q = self.Q(lam_init)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            obs = self.obs_dist.score_samples(q)\n",
    "            pred = self.pred_dist.score_samples(q)\n",
    "            this_logr = obs - pred\n",
    "            this_r = np.exp(this_logr)\n",
    "        # accept-reject\n",
    "        M = np.max(this_r)\n",
    "        t = rng.uniform(0,1,len(this_r))\n",
    "        accept_reject = np.less_equal(t,this_r/M)\n",
    "        \n",
    "        if probs_return==True:\n",
    "            up_prob = self.init_dist.logpdf(lam_init) + this_logr\n",
    "            return lam_init[accept_reject], up_prob[accept_reject]\n",
    "        else:\n",
    "            return lam_init[accept_reject]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit as timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the updates to compare: kde and GMM\n",
    "update_wkde = dci_sk_dist(init_dist,obs_kde,pred_kde,Q)\n",
    "update_wskde = dci_sk_dist(init_dist,obs_kde_silver,pred_kde,Q)\n",
    "update_wgmm = dci_sk_dist(init_dist,obs_GMM,pred_kde,Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_samples = True\n",
    "sample_fn = 'updatecirclemoons.npz'\n",
    "if load_samples==True:\n",
    "    update_load_samples = np.load(sample_fn) \n",
    "else:\n",
    "#     print('Run following code block to generate samples.')\n",
    "    raise ValueError('You need to run following code block to generate the samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to generate and save samples\n",
    "if load_samples==False:\n",
    "    # initial sample\n",
    "    monte_rng = np.random.default_rng(901234121)\n",
    "    n_monte = int(5e4) # change to 4 later.\n",
    "    \n",
    "    up_sample_dict = {key: {'sample':[],'logpdf':[],'other_logpdf':[]} for key in ['kde','gmm']}\n",
    "    up_sample_dict['kde']['silver_logpdf'] = []\n",
    "    \n",
    "    for ni in range(10):\n",
    "        tick = timeit.default_timer()\n",
    "        \n",
    "        # get initial samples\n",
    "        init4kde = init_dist.rvs(n_monte,random_state=monte_rng)\n",
    "        init4gmm = init_dist.rvs(n_monte,random_state=monte_rng)\n",
    "        \n",
    "        # get update and logpdf values\n",
    "        upkde_sample,prob_up_kde = update_wkde.accept_reject(init4kde,probs_return=True,random_state=monte_rng)\n",
    "        upgmm_sample,prob_up_gmm = update_wgmm.accept_reject(init4gmm,probs_return=True,random_state=monte_rng)\n",
    "\n",
    "        # save the values\n",
    "        up_sample_dict['kde']['sample'].append(upkde_sample)\n",
    "        up_sample_dict['kde']['logpdf'].append(prob_up_kde)\n",
    "        up_sample_dict['gmm']['sample'].append(upgmm_sample)\n",
    "        up_sample_dict['gmm']['logpdf'].append(prob_up_gmm)\n",
    "        \n",
    "        # get the evaluation of logpdf w.r.t. other distribution\n",
    "        prob_gmm_wkdeup = update_wgmm.logpdf(upkde_sample)\n",
    "        up_sample_dict['kde']['other_logpdf'].append(prob_gmm_wkdeup)\n",
    "        prob_silver_wkdeup = update_wskde.logpdf(upkde_sample)\n",
    "        up_sample_dict['kde']['silver_logpdf'].append(prob_silver_wkdeup)\n",
    "        prob_kde_wgmmup = update_wkde.logpdf(upgmm_sample)\n",
    "        up_sample_dict['gmm']['other_logpdf'].append(prob_kde_wgmmup)\n",
    "        \n",
    "        tock = timeit.default_timer()\n",
    "        print('Monte round {}: {} secs'.format(ni,tock-tick))\n",
    "        print('\\t Accepted {} kde, {} gmm.'.format(len(upkde_sample),len(upgmm_sample)))\n",
    "        print()\n",
    "    \n",
    "    # post process\n",
    "    for key in up_sample_dict.keys():\n",
    "        for key_type in up_sample_dict[key].keys():\n",
    "            up_sample_dict[key][key_type] = np.concatenate(up_sample_dict[key][key_type])\n",
    "    # reformat dict for saving\n",
    "    save_dict = {}\n",
    "    for key in up_sample_dict.keys():\n",
    "        for item in up_sample_dict[key].keys():\n",
    "            if 'other' in item:\n",
    "                save_dict[key+'W'+item] = up_sample_dict[key][item]\n",
    "            else:\n",
    "                save_dict[key+'_'+item] = up_sample_dict[key][item]\n",
    "    # save the dictionary of numpy arrays\n",
    "    np.savez(sample_fn,**save_dict)\n",
    "    \n",
    "    # load the dictionary of numpy arrays\n",
    "    update_load_samples = np.load(sample_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3587630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that update samples loaded\n",
    "for key in update_load_samples.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61641d64",
   "metadata": {},
   "source": [
    "# Compute KL-divergence and MMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ef37c",
   "metadata": {},
   "source": [
    "Here we illustrate results from theory by computing KL-divergence and the IPM using MMD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce9fd7",
   "metadata": {},
   "source": [
    "## Verification of KL-divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e946c7",
   "metadata": {},
   "source": [
    "First, KL-divergence between update and initial is equal to KL between observed and predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81118d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(up) - log(init) eval at update sample\n",
    "kl_up_init = (update_load_samples['kde_logpdf'] - init_dist.logpdf(update_load_samples['kde_sample'])).mean()\n",
    "\n",
    "# log(obs) - log(pred) eval at obs sample\n",
    "this_n = len(update_load_samples['kde_sample']) # use same size n for fair comparison\n",
    "obs_kde_resample = obs_kde.sample(this_n,random_state=sk_rand_seed) # fix random seed for reproducibility\n",
    "kl_obs_pred = (obs_kde.score_samples(obs_kde_resample) - pred_kde.score_samples(obs_kde_resample)).mean()\n",
    "print('Monte Carlo Sample n = {}'.format(this_n))\n",
    "print('KL(up||init) = {}'.format(kl_up_init))\n",
    "print('KL(obs||pred) = {}'.format(kl_obs_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_load_samples['kde_logpdf'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d0efd",
   "metadata": {},
   "source": [
    "Next we get the information gained from using CV instead of Silverman's rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(upkde) - log(upkdesilver) eval at update sample\n",
    "kl_upkde_upskde = (update_load_samples['kde_logpdf'] - update_load_samples['kde_silver_logpdf']).mean()\n",
    "\n",
    "# log(obskde) - log(obsgmm) eval at obs sample\n",
    "this_n = len(update_load_samples['kde_logpdf']) # use same size n for fair comparison\n",
    "obs_kde_resample = obs_kde.sample(this_n,random_state=sk_rand_seed) # fix random seed for reproducibility\n",
    "kl_obskde_obsskde = (obs_kde.score_samples(obs_kde_resample) - obs_kde_silver.score_samples(obs_kde_resample)).mean()\n",
    "\n",
    "print('Monte Carlo Sample n = {}'.format(this_n))\n",
    "print('KL(upkde||upskde) = {}'.format(kl_upkde_upskde))\n",
    "print('KL(obskde||obs_skde) = {}'.format(kl_obskde_obsskde))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f7a2d0",
   "metadata": {},
   "source": [
    "Compute again with a consistent sample size and number of batches for mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a variance estimate of the KL estimator\n",
    "# log(obskde) - log(obsgmm) eval at obs sample\n",
    "n_keep = int(1e4)\n",
    "var_KL_estimate = np.empty(30)\n",
    "for i in range(len(var_KL_estimate)):\n",
    "    this_n = n_keep\n",
    "    obs_kde_resample = obs_kde.sample(this_n) # fix random seed for reproducibility\n",
    "    this_kl_obskde_obsskde = (obs_kde.score_samples(obs_kde_resample) - obs_kde_silver.score_samples(obs_kde_resample)).mean()\n",
    "    var_KL_estimate[i] = this_kl_obskde_obsskde\n",
    "print('Mean KL Estimate: {}'.format(var_KL_estimate.mean()))\n",
    "print('Std. KL Estimate: {}'.format(var_KL_estimate.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbda511",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_rng = np.random.default_rng(45321) # fix random state\n",
    "var_KL_estimate_pspace = np.empty(len(var_KL_estimate))\n",
    "for i in range(len(var_KL_estimate_pspace)):\n",
    "    n_monte = n_keep*10\n",
    "    this_init_sample = init_dist.rvs(n_monte,random_state=monte_rng)\n",
    "    upkde_sample,prob_up_kde = update_wkde.accept_reject(this_init_sample,probs_return=True,random_state=monte_rng)    \n",
    "    while len(upkde_sample)<n_keep:\n",
    "        add_sample = init_dist.rvs(20*int(n_keep-len(upkde_sample)))\n",
    "        add_up_sample,new_probs = update_wkde.accept_reject(add_sample,probs_return=True,random_state=monte_rng)    \n",
    "        upkde_sample = np.concatenate([upkde_sample,add_up_sample])\n",
    "        prob_up_kde = np.concatenate([prob_up_kde,new_probs])\n",
    "    upkde_sample,prob_up_kde = upkde_sample[0:n_keep],prob_up_kde[0:n_keep]\n",
    "    prob_up_skde = update_wskde.logpdf(upkde_sample)\n",
    "    this_kl = (prob_up_kde - prob_up_skde).mean()\n",
    "    var_KL_estimate_pspace[i] = this_kl\n",
    "    print('Sample {}, n={}: KL = {}'.format(i,len(upkde_sample),this_kl))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_KL_estimate_pspace.mean(), var_KL_estimate_pspace.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d63b4",
   "metadata": {},
   "source": [
    "Next we compare the KL-divergence between updates using KDE and GMM vs. observeds using KDE and GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(upkde) - log(upgmm) eval at update sample\n",
    "kl_upkde_upgmm = (update_load_samples['kde_logpdf'] - update_load_samples['kdeWother_logpdf']).mean()\n",
    "\n",
    "# log(obskde) - log(obsgmm) eval at obs sample\n",
    "this_n = len(update_load_samples['kde_logpdf']) # use same size n for fair comparison\n",
    "obs_kde_resample = obs_kde.sample(this_n,random_state=sk_rand_seed) # fix random seed for reproducibility\n",
    "kl_obskde_obsgmm = (obs_kde.score_samples(obs_kde_resample) - obs_GMM.score_samples(obs_kde_resample)).mean()\n",
    "\n",
    "print('Monte Carlo Sample n = {}'.format(this_n))\n",
    "print('KL(upkde||upgmm) = {}'.format(kl_upkde_upgmm))\n",
    "print('KL(obskde||obsgmm) = {}'.format(kl_obskde_obsgmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b843c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convergence rate of monte-carlo scheme\n",
    "# np.sqrt(1/(this_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative KL')\n",
    "print('Updates: ', kl_upkde_upgmm/kl_up_init)\n",
    "print('Observeds: ',kl_obskde_obsgmm/kl_obs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355ecf0",
   "metadata": {},
   "source": [
    "## Verification of Pull-back IPM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1a4764",
   "metadata": {},
   "source": [
    "For reference, we provide the approximate MC convergence rate of the estimator of the MMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected convergence rate of monte-carlo estimate of updates\n",
    "n_monte_kde = len(update_load_samples['kde_sample'])\n",
    "n_monte_gmm = len(update_load_samples['gmm_sample'])\n",
    "print('MC Est. of IPM converges approx ',np.sqrt(1/n_monte_kde)+np.sqrt(1/n_monte_gmm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a3a52e",
   "metadata": {},
   "source": [
    "First, pb-IPM between update and initial is equal to pb-IPM between observed and predicted.\n",
    "\n",
    "This allows us to compute a relative IPM, which is useful for comparing it to KL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the mmd between update and initial\n",
    "mmd_upkde_init = my_mmd(Q(update_load_samples['kde_sample']),Q(init_dist.rvs(n_monte_kde,random_state=rng)))\n",
    "\n",
    "# evaluate the mmd between observed and predicted distributions\n",
    "obs_kde_resample = obs_kde.sample(n_monte_kde,random_state=sk_rand_seed) # fix random seed for reproducibility\n",
    "pred_kde_resample = pred_kde.sample(n_monte_kde,random_state=sk_rand_seed+1) # fix random seed for reproducibility\n",
    "mmd_obskde_pred = my_mmd(obs_kde_resample,pred_kde_resample)\n",
    "\n",
    "print('Monte Carlo Sample n = {}'.format(n_monte_kde))\n",
    "print('pb-MMD(up,init) = {}'.format(mmd_upkde_init))\n",
    "print('pb-MMD(obs,pred) = {}'.format(mmd_obskde_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c00eb",
   "metadata": {},
   "source": [
    "Here we evaluate the pull-back IPM (using MMD) between the update using KDE and GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate pull-back mmd between updates\n",
    "# compute Q(sampleA) and Q(sampleB) and mmd these push-forwards\n",
    "mmd_upkde_upgmm = my_mmd(Q(update_load_samples['kde_sample']),Q(update_load_samples['gmm_sample']))\n",
    "print('MC Estimate: (nkde,ngmm) = ({},{})'.format(n_monte_kde,n_monte_gmm))\n",
    "print('pb-MMD(upkde,upgmm) = {}'.format(mmd_upkde_upgmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fafefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the mmd between observed distributions\n",
    "obs_kde_resample = obs_kde.sample(n_monte_kde,random_state=sk_rand_seed) # fix random seed for reproducibility\n",
    "obs_gmm_resample = obs_GMM.sample(n_monte_gmm)[0] # random seed already fixed for GMM\n",
    "mmd_obskde_obsgmm = my_mmd(obs_kde_resample,obs_gmm_resample)\n",
    "print('MC Estimate: (nkde,ngmm) = ({},{})'.format(n_monte_kde,n_monte_gmm))\n",
    "print('MMD(obskde,obsgmm) = {}'.format(mmd_obskde_obsgmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative pb-MMD')\n",
    "print('Updates: ',mmd_upkde_upgmm/mmd_upkde_init)\n",
    "print('Observeds: ',mmd_obskde_obsgmm/mmd_obskde_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb1772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
